\abstract
Major cloud computing providers agree on denoting the flow completion time (FCT) as the primary goal to achieve in the design of a data center network (DCN). This is motivated by the fact that latency affects the performance of most cloud computer applications, such as web search, video streaming and social networking, with a direct impact on quality of experience as perceived by end users, hence ultimately on revenues.

Many existing approaches in literature rely on prioritization mechanisms at flow or packet level and schedulers in the network to reduce the average FCT, albeit for some applications also tail latency is important. To this purpose, the Shortest Remaining Processing Time (SRPT) scheduling policy is proven to be optimal when the job size is known in advance. Unfortunately this information is rarely available, therefore some proposals emulate the complementary scheme that give service first to flows that have transmitted less (Least Attained Service), exploiting a finite number of priority levels. All flows start with the highest priority and are progressively demoted to lower priorities as they receive service. The effectiveness of these algorithms, is largely improved augmenting the number of priorities. However, DCNs are usually realized with low cost commodity devices, where only few queues per port - typically two - are vacant.

The contribution of this work is to investigate the feasibility and evaluate the performance of a design which exploits multi-pathing - offered by DCN Fat-Tree topologies - to intelligently route flows across the switching fabric depending on their priority, so as to better segregate latency demanding flows. In other words, the key observation is that load balancing and prioritization can be jointly analyzed, in what multiple outgoing links together provide more priority queues than a port alone. Instead of assigning flow priorities with a scope limited to single interfaces, the problem can be addressed at data center level considering the set of links towards the flow destination as a whole. Unlike aforementioned techniques, longest flows are demoted across all priority queues of all exit interfaces, thus implying that routing choices are directly based on priority.

First, an analytical queueing model is provided for the setting of optimal parameters. Then, it will be shown through queueing model experiments that the proposed strategy indeed it is helpful under the few priority queue regime, but that long flows can be excessively penalized. Finally, extensive large scale packet level simulations in a real data center topology are conducted with Omnet++ discrete-event simulator, in order to validate the results obtained with previous steps.