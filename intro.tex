\chapter*{Introduction}
\addcontentsline{toc}{chapter}{Introduction}
In the last decades,  with the spreading of cloud services accessible to anyone, computing has undergone a remarkable evolution. Encouraged by the astonishing growth of virtualization technologies in the IT industry, as well as the availability of storage and chips at ever-more modicum prices, over-the-top (OTT) players like Google, Amazon and Microsoft, have been building datacenter hotspots all around the world. Their data center infrastructures house critical applications for most business activities, such as commercial and financial services, Web search, scientific computing, on-demand video streaming, recommendation systems, not to mention social networking and online gaming. Indeed, from small enterprises to large corporations it has been a common cost-saving strategy to offload, up to a certain extent, the deployment and operation of their own information systems to third parties, the cloud service providers. Computing resources have been being centralized in data centers facilities and shared among plenty of customers, enabling better resource utilization. \\
At the same time, cloud computing posed notable issues in the design, scalability and mantainance of systems running the aforementioned services. A major challenge is certainly the design of a huge capacity communication network hosting hundreds of thousands of servers, while guaranteeing
% that is required to simultaneously provide high throughput and low-latency, 
uninterruptible service continuity and relentless expansion. Unlike traditional TCP/IP networks such as the Internet, the data center network is characterized by a massive amount of equipment confined in a circumscribed area and administrated by a single entity, able to embrace changes to legacy protocol stack in order to accommodate their needs. 
Vast scientific literature has been produced by the research community, addressing new solutions for efficient network operations in the data center. Its peculiar environment have pushed the deployment % exploration the lack of flexibility of 
of unconventional approaches, such as centralized control and network softwarization (SDN/NFV), laying the premises for a wide transformation process in the network industry. In this sense, datacenters can be credited to having represented natural incubators for part of the evolution of telecommunication networks happening during the last few years. As a matter of fact, virtualization technologies and control plane programmability would have become soon disruptive innovations in the networking ecosystem.
%, that started to experience the same changes the IT world faced years before.
%Pushed by datacenters' needs, the research community, both from industry and academia, started to work on innovative solutions that ...  
As a result of this process, nowadays, Internet Service Providers are trying to convert their infrastructure towards the same solutions, re-architecting PoPs as small-scale datacenter, with massive employment of virtualization as regards network functions and devices. Similarly, the next generation mobile network, 5G, is going to base both its core and edge functions on the same paradigm, as revealed by its standardization and by the investments in Multi-access Edge Computing. 

In a Data Center Network (DCN) coexist traffic of a myriad applications and generally belonging to different tenants, which may have contracted a Service Level Agreement (SLA) with the provider. In general, flows with different Quality of Service (QoS) demands share the same resources. Some applications require low latency in delivering their data across servers, whereas others only require huge bandwidth but are less sensitive to timing constraints. Delays on flows that are generated by interactive applications --- like web search or social networks --- have a direct impact on the quality of user experience. Indeed, the responsiveness of these services is crucial to gain user satisfaction, hold customers in the long term and ultimately to determine revenues. As a consequence, all data center providers seek for traffic control algorithms that accomplish low response times for this kind of flow, while ensuring maximum resource utilization in the network and QoS guarantees for coexisting flows. Many of these solutions rely on advanced transport protocols and schedulers in the network to handle different flows with different priorities. The goal of this research is to devise a traffic control scheme that improves the performances of state-of-the-art schedulers, without introducing additional complexity. As will be extensively discussed hereafter, the proposed algorithm aims to exploit one property of modern data center topologies to enhance the capabilities of current scheduling strategies. 

The remainder of this work is organized as follows. Chapter \ref{ch1} is a review of the design and management principles of data center networks. It describes reference architectures for modern interconnection fabrics, adopted in practice by main players such as Google and Facebook. Then, it reports the main characteristics of data center traffic, measured in production scenarios. Finally, it exposes in details the goals of traffic control schemes and illustrates the failure of legacy protocols, like the TCP, in meeting applications requirements. Next, Chapter \ref{ch:theoretical-scheduling-bg} focuses on scheduling disciplines that best perform with data center's traffic properties in minimizing the Flow Completion Time (FCT). Some theoretical background is provided, together with two practical proposals that leverage switches priority queues (PQ) to target ideal performances. Then, Chapter \ref{ch:sdframework} presents the key idea of the present work, referred to as \emph{spatial diversity}. In the first part is illustrated qualitatively how it works and why it should give benefits. In the second part, is formulated an analytical model that will be used for setting the parameters involved in the system and adopted in its evaluation in subsequent chapters. Specifically, the validation of the system traversed two stages. Chapter \ref{ch:numerical-simulator} describes a set of results obtained through a numerical job-level simulator, which neglects all the aspects of a real data center network implementation, rather it simulates flows as jobs in an equivalent queuing model. The outcomes of this step have been of uttermost importance for understanding the advantages and the limitations of the proposed approach. Finally, its implementation in a data center network is shown in Chapter \ref{ch:dcn-simulations}, confirming similar trends to the numerical model. A broad spectrum of simulations have been carried out with the academic and educational license of the OMNeT++ framework and the INET library. Computational resources have been kindly provided by the High-Performance Computing facility of Politecnico di Torino and required engineering few MPI routines for best appreciating parallelism gains. Also, a working implementation of Data Center TCP (DCTCP) --- currently not available for the network simulator tool ---  has been delivered and it will be shared with the interested community under open source license.
%Since web applications pay also extra delays when traversing the Internet to reach the end-user, latencies inside the data center must be within tight constraints, on the order of some milliseconds. A design principle driving the development of the system is its ease of deployment with current technologies without expensive hardware/software modifications.